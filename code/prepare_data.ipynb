{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, gc, sys, warnings, random, math, psutil, pickle\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import json\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('min_rows', 200)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RAW_DATA_DIR': '../input/data-science-bowl-2019',\n",
       " 'TRAIN_DATA_DIR': '../input/processed',\n",
       " 'MODEL_CHECKPOINT_DIR': '../models/',\n",
       " 'LOGS_DIR': './logs',\n",
       " 'SUBMISSION_DIR': '../submissions/'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = json.load(open('SETTINGS.json'))\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.3 s, sys: 1.94 s, total: 38.3 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(os.path.join(settings['RAW_DATA_DIR'], 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(settings['RAW_DATA_DIR'], 'test.csv'))\n",
    "train_label_df = pd.read_csv(os.path.join(settings['RAW_DATA_DIR'], 'train_labels.csv'))\n",
    "specs_df = pd.read_csv(os.path.join(settings['RAW_DATA_DIR'], 'specs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.06 s, sys: 180 ms, total: 5.24 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def replace_4110_4100(df):\n",
    "    rep_code4110_bool = (df['title']=='Bird Measurer (Assessment)')&(df['event_code']==4110)\n",
    "    rep_code4100_bool = (df['title']=='Bird Measurer (Assessment)')&(df['event_code']==4100)\n",
    "    df['event_code'][rep_code4110_bool] = 4100\n",
    "    df['event_code'][rep_code4100_bool] = 5110 # 다른 type의 코드와 겹치지 않도록\n",
    "replace_4110_4100(train_df)\n",
    "replace_4110_4100(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create additional columns from event_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 µs, sys: 1 µs, total: 25 µs\n",
      "Wall time: 3.34 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def extract_data_from_event_code(df, columns=['correct', 'round']):\n",
    "    for col in columns:\n",
    "        col_bool = df['event_data'].str.contains(col)\n",
    "        df[col] = np.nan\n",
    "        df[col][col_bool] = df['event_data'][col_bool].apply(lambda x: json.loads(x).get(col)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 1.93 s, total: 1min 6s\n",
      "Wall time: 47.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extract_data_from_event_code(train_df)\n",
    "extract_data_from_event_code(test_df)\n",
    "        \n",
    "train_df['num_incorrect'] = np.where(train_df['correct']==0, 1, np.nan)\n",
    "train_df['num_correct'] = np.where(train_df['correct']==1, 1, np.nan)\n",
    "test_df['num_incorrect'] = np.where(test_df['correct']==0, 1, np.nan)\n",
    "test_df['num_correct'] = np.where(test_df['correct']==1, 1, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert game_time to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['game_time'] = train_df['game_time'] // 1000\n",
    "test_df['game_time'] = test_df['game_time'] // 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation by game_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 29s, sys: 21.9 s, total: 2min 51s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_agged_session(df):\n",
    "    event_code = pd.crosstab(df['game_session'], df['event_code'])\n",
    "    event_id = pd.crosstab(df['game_session'], df['event_id'])\n",
    "        \n",
    "    event_num_correct = pd.pivot_table(df[(~df['correct'].isna())], index='game_session', columns='event_code', values='num_correct', aggfunc='sum')\n",
    "    event_num_incorrect = pd.pivot_table(df[(~df['correct'].isna())], index='game_session', columns='event_code', values='num_incorrect', aggfunc='sum')\n",
    "    event_accuracy = event_num_correct/(event_num_correct+event_num_incorrect[event_num_correct.columns])\n",
    "    event_accuracy = event_accuracy.add_prefix('accuray_')    \n",
    "    \n",
    "    event_round = pd.pivot_table(df[~df['correct'].isna()], index='game_session', columns='event_code', values='round', aggfunc='max')\n",
    "    event_round = event_round.add_prefix('round_')    \n",
    "    \n",
    "    df['elapsed_time'] = df[['game_session', 'game_time']].groupby('game_session')['game_time'].diff()\n",
    "    game_time = df.groupby('game_session', as_index=False)['elapsed_time'].agg(['mean', 'max']).reset_index()\n",
    "    game_time.columns = ['game_session', 'mean_game_time', 'max_game_time']    \n",
    "    df = df.merge(game_time, on='game_session', how='left')     \n",
    "    del df['elapsed_time']\n",
    "    \n",
    "    session_extra_df = pd.concat([event_code, event_id, event_accuracy, event_round], 1)\n",
    "    session_extra_df.index.name = 'game_session'\n",
    "    session_extra_df.reset_index(inplace=True)\n",
    "    \n",
    "    session_df = df.drop_duplicates('game_session', keep='last').reset_index(drop=True)\n",
    "    session_df['row_id'] = session_df.index\n",
    "    session_df = session_df.merge(session_extra_df, how='left', on='game_session')\n",
    "    return session_df\n",
    "agged_train_df = get_agged_session(train_df)\n",
    "agged_test_df = get_agged_session(test_df)\n",
    "\n",
    "agged_train_df = agged_train_df.drop(['correct', 'round', 'num_correct', 'num_incorrect'], axis=1)\n",
    "agged_test_df = agged_test_df.drop(['correct', 'round', 'num_correct', 'num_incorrect'], axis=1)\n",
    "\n",
    "agged_test_df = agged_test_df.append(pd.DataFrame(columns=agged_train_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional training data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "CPU times: user 44 s, sys: 549 ms, total: 44.6 s\n",
      "Wall time: 44.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def gen_game_label(df):\n",
    "    num_corrects = []\n",
    "    for inst_id, one_df in tqdm_notebook(df.groupby('installation_id'), leave=False):\n",
    "        one_df = one_df[(one_df['type']=='Game')&(one_df['event_code'].isin([4020, 4025]) )]\n",
    "        for game_session, title_df in one_df.groupby('game_session'):            \n",
    "            num_correct = title_df['event_data'].str.contains('\"correct\":true').sum()\n",
    "            num_incorrect = title_df['event_data'].str.contains('\"correct\":false').sum()            \n",
    "            num_corrects.append([inst_id, game_session, num_correct, num_incorrect])\n",
    "    label_df = pd.DataFrame(num_corrects, columns=['installation_id', 'game_session', 'num_correct', 'num_incorrect'])\n",
    "    label_df['accuracy'] = label_df['num_correct'] / (label_df['num_correct']+label_df['num_incorrect'])\n",
    "    label_df['accuracy_group'] = 3\n",
    "    label_df['accuracy_group'][label_df['accuracy']==0.5] = 2\n",
    "    label_df['accuracy_group'][label_df['accuracy']<0.5] = 1\n",
    "    label_df['accuracy_group'][label_df['accuracy']==0] = 0\n",
    "    return label_df\n",
    "train_game_label_df = gen_game_label(train_df)\n",
    "test_game_label_df = gen_game_label(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate&Merge label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "CPU times: user 30.5 s, sys: 572 ms, total: 31.1 s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def gen_label(df):\n",
    "    num_corrects = []\n",
    "    for inst_id, one_df in tqdm_notebook(df.groupby('installation_id'), leave=False):\n",
    "        one_df = one_df[(one_df['type']=='Assessment')&(one_df['event_code']==4100)]\n",
    "        for game_session, title_df in one_df.groupby('game_session'):            \n",
    "            num_correct = title_df['event_data'].str.contains('\"correct\":true').sum()\n",
    "            num_incorrect = title_df['event_data'].str.contains('\"correct\":false').sum()            \n",
    "            num_corrects.append([inst_id, game_session, num_correct, num_incorrect])\n",
    "    label_df = pd.DataFrame(num_corrects, columns=['installation_id', 'game_session', 'num_correct', 'num_incorrect'])\n",
    "    label_df['accuracy'] = label_df['num_correct'] / (label_df['num_correct']+label_df['num_incorrect'])\n",
    "    label_df['accuracy_group'] = 3\n",
    "    label_df['accuracy_group'][label_df['accuracy']==0.5] = 2    \n",
    "    label_df['accuracy_group'][label_df['accuracy']<0.5] = 1\n",
    "    label_df['accuracy_group'][label_df['accuracy']==0] = 0    \n",
    "    return label_df\n",
    "train_label_df = gen_label(train_df)\n",
    "test_label_df = gen_label(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303319, 456)\n",
      "(28445, 456)\n",
      "CPU times: user 5.62 s, sys: 516 ms, total: 6.14 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agged_train_df = agged_train_df.merge(train_label_df, on=['game_session', 'installation_id'], how='left')\n",
    "agged_train_df = agged_train_df.merge(train_game_label_df, on=['game_session', 'installation_id'], how='left', suffixes=('', '_game'))\n",
    "agged_test_df = agged_test_df.merge(test_label_df, on=['game_session', 'installation_id'], how='left')\n",
    "agged_test_df = agged_test_df.merge(test_game_label_df, on=['game_session', 'installation_id'], how='left', suffixes=('', '_game'))\n",
    "agged_test_df = agged_test_df[agged_train_df.columns]\n",
    "print(agged_train_df.shape)\n",
    "print(agged_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17690, 456)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agged_train_df[(agged_train_df['accuracy_group'] >= 0)&(agged_train_df['type']=='Assessment')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8c0157add041fabfd28cd7281ea685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8266958d444be6b56443ad98aee75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "17690 2018\n",
      "CPU times: user 41.5 s, sys: 512 ms, total: 42 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_train_sample_indices(df):\n",
    "    sample_indices = []\n",
    "    inst_indiecs = []    \n",
    "    df_groups = df.groupby('installation_id').groups\n",
    "    for inst_idx, indices in enumerate(tqdm_notebook(df_groups.values())):\n",
    "        one_df = df.iloc[indices].reset_index(drop=True)\n",
    "        assessment_start_indices = one_df[(one_df['type']=='Assessment')&\n",
    "                                          (one_df['accuracy_group']>=0)\n",
    "                                         ].index\n",
    "        for num, start_index in enumerate(assessment_start_indices):\n",
    "            sample_indices.append( one_df.iloc[:start_index+1]['row_id'].tolist() )\n",
    "            inst_indiecs.append(inst_idx)            \n",
    "    return sample_indices, inst_indiecs\n",
    "\n",
    "train_samples, train_groups = get_train_sample_indices(agged_train_df)\n",
    "test_samples, test_groups = get_train_sample_indices(agged_test_df)\n",
    "print(len(train_samples), len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f868669f4b9f4b57a267832b7711b0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee19aa4b97b455a84dd90f9c6129861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "41194 4225\n",
      "CPU times: user 44.1 s, sys: 686 ms, total: 44.8 s\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_train_game_sample_indices(df):\n",
    "    sample_indices = []\n",
    "    inst_indiecs = []    \n",
    "    df_groups = df.groupby('installation_id').groups\n",
    "    for inst_idx, indices in enumerate(tqdm_notebook(df_groups.values())):\n",
    "        one_df = df.iloc[indices].reset_index(drop=True)\n",
    "        assessment_start_indices = one_df[(one_df['type']=='Game')&\n",
    "                                          (one_df['accuracy_group_game']>=0)\n",
    "                                         ].index\n",
    "        for num, start_index in enumerate(assessment_start_indices):\n",
    "            sample_indices.append( one_df.iloc[:start_index+1]['row_id'].tolist() )\n",
    "            inst_indiecs.append(inst_idx)            \n",
    "    return sample_indices, inst_indiecs\n",
    "\n",
    "train_game_samples, train_game_groups = get_train_game_sample_indices(agged_train_df)\n",
    "test_game_samples, test_game_groups = get_train_game_sample_indices(agged_test_df)\n",
    "print(len(train_game_samples), len(test_game_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agged_train_df = agged_train_df.fillna(0)\n",
    "agged_test_df = agged_test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert categorical data to corresponding index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de294c897ebc4c58b5287986e67920d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 8.64 s, sys: 2.29 s, total: 10.9 s\n",
      "Wall time: 916 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_df = pd.concat([agged_train_df, agged_test_df])\n",
    "cate_cols = ['title', 'type', 'world']\n",
    "cont_cols = ['event_count', 'game_time', 'max_game_time']\n",
    "extra_cont_cls = list(agged_train_df.columns[15:-4]) # except 2000\n",
    "mappers_dict = {}\n",
    "\n",
    "cate_offset = 1\n",
    "for col in tqdm_notebook(cate_cols):    \n",
    "    cate2idx = {}\n",
    "    for v in all_df[col].unique():\n",
    "        if (v != v) | (v == None): continue \n",
    "        cate2idx[v] = len(cate2idx)+cate_offset\n",
    "    mappers_dict[col] = cate2idx    \n",
    "    agged_train_df[col] = agged_train_df[col].map(cate2idx).fillna(0).astype(int)\n",
    "    agged_test_df[col] = agged_test_df[col].map(cate2idx).fillna(0).astype(int)\n",
    "    cate_offset += len(cate2idx)\n",
    "del all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.5 s, sys: 1.85 s, total: 4.35 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.makedirs(settings['TRAIN_DATA_DIR'], exist_ok=True)\n",
    "torch.save([agged_train_df, agged_test_df, mappers_dict, cate_offset, cate_cols, cont_cols, extra_cont_cls, \n",
    "            train_samples, train_groups, test_samples, train_game_samples, test_game_samples],\n",
    "           os.path.join(settings['TRAIN_DATA_DIR'], 'bowl.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save([agged_train_df.columns, mappers_dict, cate_offset, cate_cols, cont_cols, extra_cont_cls],\n",
    "           os.path.join(settings['TRAIN_DATA_DIR'], 'bowl_info.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
